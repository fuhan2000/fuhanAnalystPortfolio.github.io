<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Scikit-learn Classification</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class=""></a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Portfolio Main Page</a></li>

						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/fuhhanchang/" class="icon brands alt fa-linkedin"><span class="label">linkedin</span></a></li>
							<li><a href="https://github.com/fuhan2000" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									
									<h1>Scikit-learn Classification <br />
										</h1>
									<p>We are trying to determine if an existing bank customer will take up a new credit card based upon
										his behavior with regards to twenty other products.
									</p>
								</header>

								<div class="image main"><img src="images/unit13_ex1/unit13_roc.png" alt="" /></div>
								<p>Prior to this, I have already run the dataset through SAP Predictive Analytics. The Predictive Power (KI) is 0.35 and Prediction Confidence (KR) is 0.98. 
								The ROC curve is better than a random model but not great. In an ideal world, you will add additional columns to improve KI and ROC. In real-life, the data might not be there 
								or there may be privacy laws that prevent the usage of those data. The best the bank can do is to provide data on customer behavior towards twenty other products.</p>

								<p> Here I will clean up the data in SQL, use python to do some transformation and finally use Random Forest and neural network to do classification. I will also comment
									on SAP output on the same dataset.
								</p>

								
								<p><br/></p>
								<h2>Importing Data into MySQL</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/unit13_sql.png" alt=""></div></figure>
								<p><br/></p>
								<p> These are some of the codes I use to create a table. The table is 268747 rows x 269 columns. </p>
								<blockquote>
									LOAD DATA INFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/forecast_propensity_new_card_unit13_ex1.csv'<br/>
									INTO TABLE forecast_propensity_new_card <br/>
									FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'<br/>
									-- IGNORE 1 ROWS <br/>
									(.. many_columnsNames..)</blockquote>

								<p>Then load my data into the table. Some comments on the columns names:<br/>
								<table style="width:100%">
									<tr>
										<th>Column Name</th>
										<th>Description</th>
									</tr>
									<tr>
										<td>KxId</td>
										<td>created by HANA</td>
									</tr>
									<tr>
										<td>KxTimeStamp</td>
										<td>created by HANA to show the reference time selected by end user</td>
									</tr>
									<tr>
										<td>GENDER_TYPE</td>
										<td>gender of the customer</td>
									</tr>
									<tr>
										<td>AGE_GROUP</td>
										<td>age group of the customer</td>
									</tr>
									<tr>
										<td>EMAIL_FLG</td>
										<td>customer's email</td>
									</tr>
									<tr>
										<td>ADDRESS_FLG</td>
										<td>customer's address</td>
									</tr>
									<tr>
										<td>TENURE</td>
										<td>how long the customer has been with the bank</td>
									</tr>
									<tr>
										<td>PROD_6M6B_PRODUCT_10xxxxx_SUM_y_AMOUNT</td>
										<td>sum of sales amount for product 10xxxxx (6-y) months before reference date</td>
									</tr>
									<tr>
										<td>PROD_6M6B_PRODUCT_1000367_SUM_0_AMOUNT</td>
										<td>sum of sales amount for product 1000367 six months before reference date</td>
									</tr>	
									<tr>
										<td>PROD_6M6B_PRODUCT_1000367_SUM_5_AMOUNT</td>
										<td>sum of sales amount for product 1000367 one month before reference date</td>
									</tr>
									<tr>
										<td>PROD_6M6B_SUM_0_AMOUNT</td>
										<td>sum of sales amount per month six months ago</td>
									</tr>		
									<tr>
										<td>PROD_6M6B_SUM_0_DISCOUNT</td>
										<td>sum of discount per month six months ago</td>
									</tr>	
									<tr>
										<td>SUM_SUM_AMOUNT</td>
										<td>sum of sales amount over the past six months</td>
									</tr>	
									<tr>
										<td>SUM_SUM_DISCOUNT</td>
										<td>sum of discount amount over the past six months</td>
									</tr>	
									<tr>
										<td>CNT_6M6B_CNT_0_NoOperande</td>
										<td>frequency count of number of transactions per month six months ago</td>

									</tr>
								
								</table>


								</p>
								<h2>Cleaning Data in SQL</h2>
								<blockquote>update forecast_propensity_new_card as f<br/>
									set f.PROD_6M6B_PRODUCT_1016578_SUM_0_AMOUNT =0<br/>
									where f.PROD_6M6B_PRODUCT_1016578_SUM_0_AMOUNT ='';</blockquote>

								<p>There is a lot of empty fields which i fill with zeros.</p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/unit13_age_group_orig.png" alt=""></div></figure>
								<p>AGE_GROUP, EMAIL_FLG, ADDRESS_FLG is tidied up. </p>
								
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/age_group_new.png" alt=""></div></figure>
								<p><br/></p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/new_email.png" alt=""></div></figure>
								<p><br/></p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/new_addr.png" alt=""></div></figure>
								
								<h2>Exporting to CSV </h2>
								<blockquote>-- export as csv<br/>
									SELECT *<br/>
									FROM forecast_propensity_new_card<br/>
									INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/clean_forecast_propensity_new_card.csv' <br/>
									LINES TERMINATED BY '\r\n';<br/>
									</blockquote>

								<p><br/></p>
								<h2>Importing Libraries</h2>
								<blockquote>#Importing required packages.<br/>
									import pandas as pd<br/>
									import seaborn as sns<br/>
									import matplotlib.pyplot as plt<br/>
									from sklearn.ensemble import RandomForestClassifier<br/>
									
									from sklearn.neural_network import MLPClassifier<br/>
									from sklearn import linear_model<br/>
									#<br/>
									from sklearn.metrics import confusion_matrix, classification_report<br/>
									from sklearn.metrics import mean_squared_error, r2_score<br/>
									from sklearn.preprocessing import StandardScaler, LabelEncoder<br/>
									from sklearn.model_selection import train_test_split<br/>
									%matplotlib inline</blockquote>
								<p><br/></p>
								<h2>Read into data frame</h2>
								<blockquote># read into data frame<br/>
									predict_propensity = pd.read_csv(r'E:\project\mysql_unit13_ex1_classify\clean_forecast_propensity_new_card.csv')
									predict_propensity.head()<br/>
								</blockquote>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/df_head.png" alt=""></div></figure>
								<p><br/></p>
								<h2>Checking for NULL</h2>
								<blockquote># checking to see if there's any null variables<br/>
									# <br/>
									predict_propensity.isnull().sum().sort_values(ascending = False)</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/any_nan.png" alt=""></div></figure>
								<p><br/></p>
								<p>We do not have any null values.</p>
								<p><br/></p>
								<h2>Checking TARGET column</h2>
								<blockquote># Target 0: customer did not purchase at least one of the card<br/>
									# Target 1: customer did purchase.<br/>
									predict_propensity['TARGET'].unique()</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/array_0_1.png" alt=""></div></figure>
								
								<p><br/></p>
								<blockquote>sns.countplot(predict_propensity['TARGET'])</blockquote>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/countplot.png" alt=""></div></figure>
								<p><br/></p>
								<blockquote># Get actual count of number of Target '0' and '1'<br/>
									# does not matter if u use 'KxId'<br/>
									By_Target = predict_propensity.groupby('TARGET')<br/>
									By_Target = By_Target.count()<br/>
									By_Target = By_Target[['KxId']]<br/>
									By_Target</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/kxid.png" alt=""></div></figure>
								<p>We have 5816 Target '1' and 262931 '0'</p>

								<h2>Encode GENDER_TYPE</h2>
								<blockquote>def GENDER_TYPE_encode(n):<br/>
									if n == 'M':<br/>
										return 1<br/>
									else:<br/>
										return 0<br/>
								predict_propensity['GENDER_TYPE_enc'] = predict_propensity.GENDER_TYPE.apply(GENDER_TYPE_encode)<br/>
								predict_propensity</blockquote>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/gender_enc.png" alt=""></div></figure>
								<p>GENDER_TYPE: M =1, F=0</p>
								<h2>Encode AGE_GROUP</h2>
								<blockquote>def AGE_GROUP_encode(n):<br/>
									if n== "<=17":<br/>
										return 0<br/>
									elif n== "18 - 25":<br/>
										return 1<br/>
									elif n=="26 - 35":<br/>
										return 2<br/>
									elif n=="36 - 45":<br/>
										return 3<br/>
									elif n=="46 - 60":<br/>
										return 4<br/>
									elif n==">60":<br/>
										return 5<br/>
									elif n=="-":<br/>
										return 6<br/>
									else:<br/>
										return 7<br/>
								predict_propensity['AGE_GROUP_enc'] = predict_propensity.AGE_GROUP.apply(AGE_GROUP_encode)</blockquote>

								<h2>check data frame data types</h2>
								<blockquote>predict_propensity.dtypes</blockquote>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/dtypes.png" alt=""></div></figure>
								<p><br/></p>
								<h2>Training and testing datasets</h2>
								<blockquote># Now seperate the dataset as response variable and feature variabes<br/>
									# capital X <br/>
									# small y <br/>
									X = predict_propensity.drop(['KxId', 'KxTimeStamp','GENDER_TYPE', 'AGE_GROUP', 'TARGET'], axis = 1)<br/>
									y = predict_propensity['TARGET']<br/>
									#Train and Test splitting of data <br/>
									# test size is 20%<br/>
									X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)<br/>
								</blockquote>
								<h2>Apply Standard Scaling</h2>
								<blockquote>
									# Applying Standard scaling to get optimized result<br/>
									sc = StandardScaler()<br/>
									X_train = sc.fit_transform(X_train) # do fit and transform<br/>
									X_test = sc.transform(X_test) #do only transform<br/>
								</blockquote>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/xtrain_xtest.png" alt=""></div></figure>
								<p><br/></p>
								<h2>Random forest classifier</h2>
								<blockquote># use 200 trees in the forest<br/>
									#<br/>
									rfc = RandomForestClassifier(n_estimators=200)<br/>
									# fit our training data<br/>
									rfc.fit(X_train, y_train)<br/>
									pred_rfc = rfc.predict(X_test)</blockquote>
									<blockquote>#Let's see how our model performed<br/>
										# y_test is the actual value<br/>
										# pred_rfc is the predicted value<br/>
										# classification_report(y_true, y_pred)<br/>
										print(classification_report(y_test, pred_rfc))</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/rfc_classify.png" alt=""></div></figure>
									<p><br/></p>
									<p>precision(1): precision in determining customer who do get product = 3%<br/>
									precision(0): precision in determining customer who do not get product = 98%<br/>
									overall precision is 96%. We are not good with predicting customer who will get the product.
									</p>
									<blockquote>#Confusion matrix for the random forest classification<br/>
										# sklearn.metrics.confusion_matrix(y_true, y_pred)<br/>
										
										cf_matrix = confusion_matrix(y_test, pred_rfc)<br/>
										cf_matrix</blockquote>
										<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/cf_matrix.png" alt=""></div></figure>
										<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/tn.png" alt=""></div></figure>
									<p>Our True Positive is only 4. This fits with the low precision(1) of 3%. Our model is better at predicting customer who will not choose the product as seen in 
										True Negative of 52487.
									</p>

									<h2>Accuracy score from RFC</h2>
									<blockquote># sklearn.metrics.accuracy_score(y_true, y_pred)<br/>
										from sklearn.metrics import accuracy_score<br/>
										myac = accuracy_score(y_test, pred_rfc)<br/>
										myac</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/myac.png" alt=""></div></figure>
									<p>Our RFC is about 98% accurate.</p>

									<h2>Neural Network Multi-layer Perceptron classifier</h2>
									<blockquote># NN Multi-layer Perceptron classifier<br/>
										# we will have three layers.<br/>
										# each layer has 11 nodes<br/>
										#<br/>
										mlpc = MLPClassifier(hidden_layer_sizes=(11,11,11), max_iter=5000)<br/>
										mlpc.fit(X_train, y_train)<br/>
										pred_mlpc = mlpc.predict(X_test)
									</blockquote>
									<blockquote># Let see how our model performed<br/>
										print(classification_report(y_test, pred_mlpc ))<br/>
										print(confusion_matrix(y_test, pred_mlpc ))
									</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/nn_classi.png" alt=""></div></figure>
									<p>Our TN is 52561 but our TP is too low at 7. This TP is only marginally better than RFC's TP.</p>

									<h2>Accuracy score from NN</h2>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/accu_nn.png" alt=""></div></figure>
									<p><br/></p>
									<h2>Comment on accuracy score from RFC and NN</h2>
									<p>Both RFC and NN are around 98% accurate.</p>

									<h2>Linear Regression Model</h2>
									<blockquote># Create linear regression object<br/>
									reg = linear_model.LinearRegression()<br/>
									# Train the model using the training sets<br/>
									reg.fit(X_train, y_train)<br/>
									# Make predictions using the testing set<br/>
									y_pred = reg.predict(X_test)<br/>

									# The coefficients<br/>
									# disable this as I have 266 features<br/>
									# print('Coefficients: \n', reg.coef_)<br/>
									# The mean squared error<br/>
									print('Mean squared error: %.2f'% mean_squared_error(y_test, y_pred))<br/>
									# The coefficient of determination: 1 is perfect prediction<br/>
									print('Coefficient of determination: %.2f'% r2_score(y_test, y_pred))</blockquote>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/mse.png" alt=""></div></figure>
									<p>I have disabled the printing of the 266 coefficients for this model. I have only printed the MSE and coefficient of determination. 
										MSE should be as low as possible. coefficient of determination should be as close to 1.</p>
									
									<h2>Comparision with SAP Output</h2>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/con_sap.png" alt=""></div></figure>
									<p>In SAP, only eleven variables are kept. These are the variables deemed to have significant impacts on the model outcome. </p>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/automl.png" alt=""></div></figure>
									<p>In our case, the model stop at Iterations:6 with KI = 0.3509 and KR = 0.9837.</p>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/sc.png" alt=""></div></figure>
									<p>To see the coefficients of the eleven variables, we can access the score card.</p>

									<h2>SAP Exclusion Step</h2>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/variable_ex.png" alt=""></div></figure>
									<p> We can see which variables were excluded at which steps. </p>
									<h2>SAP Confusion Matrix</h2>
									<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/unit13_ex1/sap_conf.png" alt=""></div></figure>
									<p>The SAP model is better than my python models. TP is 97 while TN is 51789. But still TP is only 0.18%. So SAP model is better at predicting customer who will not 
									get the product. You can compare the figures here directly with their python counterparts as I have set the testing sample size at 53750 (or 20% of total sample size 268747). <br/>
									The fact that SAP perform better should not be a surprise as they will use AutoML in determining the best classification model. In my python model, i only use 
									RFC(200 trees) and NN (3 hidden layers with 11 nodes each, 5000 iterations).
									</p>
									
									<h2>Advice to the bank</h2>
									<p>The model can be better if I can link other data like income, account balances, various loans' data to it. 
									Just having data on his behavior with regards to twenty other products is not good enough to classify whether he will take up a new credit card. 
									There is too many zeros at CNT_6M6B_xx and PROD_6M6B_xx variables.</p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<nav id="nav">
							<ul class="links">
								<li><a href="index.html">Portfolio Main Page</a></li>
	
							</ul>
						</nav>

						<section class="split contact">




						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; fuhan</li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>