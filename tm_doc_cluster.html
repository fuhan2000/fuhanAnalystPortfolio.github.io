<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Topic Modeling Doc Cluster</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class=""></a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Portfolio Main Page</a></li>

						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/fuhhanchang/" class="icon brands alt fa-linkedin"><span class="label">linkedin</span></a></li>
							<li><a href="https://github.com/fuhan2000" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									
									<h1>topic Modeling for document clustering</h1>
									<p>We use topic modeling to do document clustering</p>
								</header>

								<div class="image main"><img src="images/tm_doc_cluster/tm_doc_cluster.png" alt="" /></div>
								<p>According to <a href="https://en.wikipedia.org/wiki/Topic_model">wikipedia</a>, a topic model is a type of statistical model for discovering the 
									abstract "topics" that occur in a collection of documents.</p>

								<p>Let say I have four types of documents that deal with computer, biology, physics and history, I might get something as shown below if I run them through 
									topic modeling:</p>
								<ul>
									<li>topics1: ssd, harddisk, ram, hdmi</li>
									<li>topics2: gene, genetics, active transport, antibody</li>
									<li>topics3: potential, kinetic, energy, thermal</li>
									<li>topics4: greek, roman, empire, caesar</li>
								  </ul> 
								<p>In other words, I will get four clusters. I will get text data from customers' reviews on automotive, books and cell phones and run them through topic 
									modeling. In the end, I will explain why topic modeling behave the way it does and why my amazon dataset is not that suited for this type of clustering.
								</p> 

								<h2>Data Source</h2>
								<p>The data source is provided by Jianmo Ni of UCSD at his <a href="https://nijianmo.github.io/amazon/index.html">github</a>.</p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/webpage.png" alt=""></div></figure>
								<p>My automotive, books and cell phone data are obtained from the above three links. </p>

								<h2>Import Data</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df1.png" alt=""></div></figure>
								<p>We import automotive data into df1.</p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df1_num_w.png" alt=""></div></figure>
								<p>num_words will keep a count of the number of words in reviewText. We will only keep those rows where reviewText has at least two words. df1 now have 9530 rows. </p>

								<h2>Books df2</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df2.png" alt=""></div></figure>
								<p>df2 will have 9694 rows. </p>

								<h2>Cell phone df3</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df3.png" alt=""></div></figure>
								<p>df3 will have 9712 rows. </p>

								<h2>text processing</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/text_process.png" alt=""></div></figure>
								<p>We change all the text to lowercase, remove special characters and remove multiple spaces for df1. </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df2_df3.png" alt=""></div></figure>
								<p>We did the same for df2 and df3. </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/drop.png" alt=""></div></figure>
								<p>We drop the num_words as we no longer need it. </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/class.png" alt=""></div></figure>
								<p>We assign class of auto to d1, book to df2 and cell to df3.</p>

								<h2>Dataframe df</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/df_csv.png" alt=""></div></figure>
								<p>df is made up of df1, df2 and df3. It has 28936 rows made of 9530 df1, 9694 df2 and 9712 df3. I did a backup of df.</p>
								<h2>topic modeling with ktrain</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/tm.png" alt=""></div></figure>
								<p>More information on ktrain can be found <a href="https://github.com/amaiya/ktrain">here</a>. We will create a ktrain model with 10,000 features. 
									By default Latent Dirichlet Allocation (LDA) is used. NMF is another option in ktrain.text.get_topic_model() as per its source code 
									<a href="https://github.com/amaiya/ktrain/blob/master/ktrain/text/eda.py">here</a>. But I will stay with LDA.</p>
								
								<p>print_topics() print out all the words that occurs frequently together. In topic 0, beautiful, dawn, super and land tend to occur together.  </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/topic120.png" alt=""></div></figure>
								<p>In total there are 120 topics. </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/tm_build.png" alt=""></div></figure>
								<p>As per source code, this build the document-topic distribution and those documents whose highest topic probability is less than 0.25 will be filtered out.</p>

								<p>After filtering, I want to ensure my list_reviews and list_class have the same lengths. </p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/topic7.png" alt=""></div></figure>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/topic27.png" alt=""></div></figure>
								<p>As can be seen above, topic 7 has the most counts of 10185. topic 27 has a count of one. Note that I have only captured the top and bottom part of print_topics() 
									for sake of brevity.</p>

								<h2>Document visualization of all documents</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/this_is.png" alt=""></div></figure>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/tm_doc_cluster.png" alt=""></div></figure>
								<p>topic 7 with the highest count of 10185 made up the reddish-brown dots.</p>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/mouse_over_br.png" alt=""></div></figure>
								<p>If i mouse over the reddish-brown dots, a tooltip will appear.</p>

								<h2>Document visualization topic 66 & 100</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/doc_66_100.png" alt=""></div></figure>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/doc_66_100_2.png" alt=""></div></figure>
								<p>The small blue cluster at (30,10) is for topic 66. I believe it is commenting about cell phones. The larger cluster of topic 100 should be about car. 
									In this case, the algorithm is able to distinguish between the two.   </p>

								<h2>DOCUMENT VISUALIZATION TOPIC 71 & 100</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/doc_71_100.png" alt=""></div></figure>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/doc_71_100_2.png" alt=""></div></figure>
								<p>Both topic 71 (blue) and 100 (purple) are about automotive. So it should not be surprising that these two clusters are indistinguishable. </p>

								<h2>Test with random texts on book</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/raw_text1.png" alt=""></div></figure>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/predict_rt1.png" alt=""></div></figure>

								<p>I copied the rawtext from an amazon review. The algorithm is picking up on the reviewer opinion of the book. The algorithm is sensing that this text is 
									associated with 'like just dont'.</p>
								
								<h2>TEST WITH RANDOM TEXTS ON automotive</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/raw_text2.png" alt=""></div></figure>
								<p>Above is a review for 2019 Toyota 4Runner TRD. Notice that the output is also 'like just dont'. I will say that this clustering is not very useful to business.</p>

								<h2>TEST WITH RANDOM TEXTS ON AUTOMOTIVE(2)</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/raw_text3.png" alt=""></div></figure>
								<p>Another review of the Toyota 4Runner now got assigned a topic of 'read reading world'. I feel this clustering is not very useful for business as I associate
									read with books.
								</p>
								
								<h2>TEST WITH RANDOM TEXTS ON cell phones</h2>
								<figure style="max-width:2388pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image"><div><img src="images/tm_doc_cluster/raw_text4.png" alt=""></div></figure>
								<p>This review of a cell phone also got assigned 'like just dont'. Not very useful.</p>

								<h2>What i considered good clustering</h2>
								<p>This bring me back to what i wrote in the beginning about four types of documents that belong to computer, biology, physics and history. 
									In those cases if the algorithm is able to return something like 'potential, kinetic, energy, thermal', then it will be understandable to us.</p>
								
								<p>In this case, we are not able to do that. This is not an attack on topic modeling but rather I would say that my data is not suited for this 
									algorithm. The algorithm seem to pick up on the reviewers' sentiments towards a product (like, just, dont).</p>

								<p>Had I fed automobile manuals, cell phone manuals and some kind of manual on how to print good books, I am sure this algorithm will work. We might then get:</p>
								<ul>
									<li>topic 0: piston, door, brake</li>
									<li>topic 1: hardcover, paperback, author</li>
									<li>topic 2: touchscreen, battery, antenna </li>
								</ul>

								<p>This type of clustering is more useful to business.</p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<nav id="nav">
							<ul class="links">
								<li><a href="index.html">Portfolio Main Page</a></li>
	
							</ul>
						</nav>

						<section class="split contact">




						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; fuhan</li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>